{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu\n"
     ]
    }
   ],
   "source": [
    "# gpu using\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "    print('Using gpu')\n",
    "else:\n",
    "    config = tf.ConfigProto(device_count={\"CPU\": 32},\n",
    "                            inter_op_parallelism_threads=32,\n",
    "                            intra_op_parallelism_threads=32)\n",
    "K.set_session(K.tf.Session(config=config))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=20, \n",
    "                              width_shift_range=5.0,\n",
    "                              height_shift_range=5.0,\n",
    "                              shear_range=5.0,\n",
    "                              featurewise_center=False,\n",
    "                              zoom_range=[0.8, 1.2],\n",
    "                              fill_mode='nearest',\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=False,\n",
    "                              featurewise_std_normalization=False)\n",
    "\n",
    "train_gen= datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='binary')\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    'val',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 244s 651ms/step - loss: 0.6454 - acc: 0.6211 - val_loss: 0.5505 - val_acc: 0.7219\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 161s 430ms/step - loss: 0.5628 - acc: 0.7126 - val_loss: 0.4899 - val_acc: 0.7778\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 161s 429ms/step - loss: 0.5092 - acc: 0.7582 - val_loss: 0.4476 - val_acc: 0.7906\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.4701 - acc: 0.7881 - val_loss: 0.4149 - val_acc: 0.8259\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.4416 - acc: 0.8012 - val_loss: 0.4210 - val_acc: 0.8088\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.4226 - acc: 0.8137 - val_loss: 0.3937 - val_acc: 0.8483\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 160s 426ms/step - loss: 0.4079 - acc: 0.8205 - val_loss: 0.4240 - val_acc: 0.7981\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 160s 426ms/step - loss: 0.3897 - acc: 0.8308 - val_loss: 0.3921 - val_acc: 0.8237\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3743 - acc: 0.8400 - val_loss: 0.3592 - val_acc: 0.8291\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3647 - acc: 0.8446 - val_loss: 0.3289 - val_acc: 0.8632\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 160s 428ms/step - loss: 0.3544 - acc: 0.8488 - val_loss: 0.3494 - val_acc: 0.8462\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3475 - acc: 0.8547 - val_loss: 0.3237 - val_acc: 0.8494\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 160s 426ms/step - loss: 0.3420 - acc: 0.8559 - val_loss: 0.3194 - val_acc: 0.8611\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3331 - acc: 0.8597 - val_loss: 0.3564 - val_acc: 0.8494\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3195 - acc: 0.8678 - val_loss: 0.3049 - val_acc: 0.8665\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3124 - acc: 0.8686 - val_loss: 0.3055 - val_acc: 0.8718\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.3048 - acc: 0.8738 - val_loss: 0.2824 - val_acc: 0.8771\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 160s 426ms/step - loss: 0.2999 - acc: 0.8765 - val_loss: 0.2884 - val_acc: 0.8718\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2917 - acc: 0.8799 - val_loss: 0.2707 - val_acc: 0.8878\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2890 - acc: 0.8802 - val_loss: 0.2952 - val_acc: 0.8782\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2807 - acc: 0.8852 - val_loss: 0.2523 - val_acc: 0.9006\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2794 - acc: 0.8833 - val_loss: 0.2631 - val_acc: 0.8803\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2689 - acc: 0.8886 - val_loss: 0.2820 - val_acc: 0.8846\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 160s 428ms/step - loss: 0.2710 - acc: 0.8873 - val_loss: 0.2802 - val_acc: 0.8782\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2631 - acc: 0.8902 - val_loss: 0.2858 - val_acc: 0.8707\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 160s 428ms/step - loss: 0.2606 - acc: 0.8928 - val_loss: 0.2760 - val_acc: 0.8643\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 160s 428ms/step - loss: 0.2625 - acc: 0.8900 - val_loss: 0.2404 - val_acc: 0.8964\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2512 - acc: 0.8990 - val_loss: 0.2492 - val_acc: 0.8910\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2578 - acc: 0.8949 - val_loss: 0.2620 - val_acc: 0.8857\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 160s 427ms/step - loss: 0.2471 - acc: 0.8990 - val_loss: 0.3011 - val_acc: 0.8707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19aaa650a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 24000\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 1000\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=int(nb_train_samples // batch_size),\n",
    "    epochs=30,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=int(nb_validation_samples // batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1    10   100  1000 10000 10001 10002 10003 10004 10005]\n",
      "Test images:  ['test1/1.jpg', 'test1/10.jpg', 'test1/100.jpg', 'test1/1000.jpg', 'test1/10000.jpg', 'test1/10001.jpg', 'test1/10002.jpg', 'test1/10003.jpg', 'test1/10004.jpg', 'test1/10005.jpg']\n",
      "[[[ 97  67  40]\n",
      "  [100  65  39]\n",
      "  [102  61  36]\n",
      "  ...\n",
      "  [207 108  76]\n",
      "  [218 121  87]\n",
      "  [173  84  48]]\n",
      "\n",
      " [[ 94  64  37]\n",
      "  [ 93  57  31]\n",
      "  [103  62  37]\n",
      "  ...\n",
      "  [207 106  81]\n",
      "  [217 118  89]\n",
      "  [174  81  51]]\n",
      "\n",
      " [[ 97  67  40]\n",
      "  [100  64  38]\n",
      "  [108  68  43]\n",
      "  ...\n",
      "  [207 106  84]\n",
      "  [219 118  94]\n",
      "  [182  86  59]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[199 187 181]\n",
      "  [209 195 189]\n",
      "  [209 195 189]\n",
      "  ...\n",
      "  [135 142 159]\n",
      "  [118 133 148]\n",
      "  [108 129 145]]\n",
      "\n",
      " [[187 176 172]\n",
      "  [198 187 183]\n",
      "  [204 189 186]\n",
      "  ...\n",
      "  [ 94 112 110]\n",
      "  [ 96 117 117]\n",
      "  [ 88 111 114]]\n",
      "\n",
      " [[175 172 168]\n",
      "  [190 182 179]\n",
      "  [204 190 188]\n",
      "  ...\n",
      "  [193 184 195]\n",
      "  [129 138 148]\n",
      "  [ 70  94 102]]]\n",
      "Images arrays  (12500, 150, 150, 3)\n",
      "(12500, 1)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "paths = ['test1/' + i for i in os.listdir('test1')]\n",
    "indexes = np.array([int(file.replace('.jpg', '')) for file in os.listdir(\"test1\")])\n",
    "print(indexes[:10])\n",
    "print(\"Test images: \", paths[:10])\n",
    "images = np.array([cv2.resize(cv2.imread(img_path, cv2.COLOR_BGR2RGB), (150, 150)) for img_path in paths])\n",
    "print(images[0])\n",
    "print(\"Images arrays \", images.shape)\n",
    "labels = model.predict_classes(images)\n",
    "print(labels.shape)\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "id       \n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "5       0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame({'label': labels.flatten()})\n",
    "frame.index = np.array(indexes, dtype='int32')\n",
    "frame.index.name='id'\n",
    "frame.sort_values(by='id', inplace=True)\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_csv(\"submission\" + str(len(os.listdir())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
